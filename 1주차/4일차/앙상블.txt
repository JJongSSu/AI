앙상블 : 보팅, 베깅, 부스팅

보팅
    여러 개의 다른 모델이 예측한 결과를 투표/평균을 통해 최종 예측결과를 선정
    
    하드 보팅 : 다수결
    소프트 보팅 : 각 확률의 평균

    hardmax : 양립할 수 없는 관계
    softmax : 확률을 통해 결과 예측

배깅
    하나의 모델을 조건을 다르게 해서 여러번 실행했을 때의 투표값
    독립적으로 결과 처리
    과대적합 방지

    랜덤 포레스트

부스팅
    여러 개의 모델이 순차적으로 학습-예측하며 잘못 예측한 데이터에 가중치를 부여해 오류를 개선해 나가면서 학습하는 방식
    (결정트리 모형을 베이스로 사용)
    전에 나온 결과가 다음 결과에 영향을 미침
    과소적합 방지

    - 에이다 부스팅
    
    - 그레디언트 부스팅
        경사하강법 사용 -> 최적의 가중치(파라미터) 찾아냄
    
    - XG 부스팅
        그레디언트 부스팅에서 발생하는 과대적합을 alpha를 통해 방지

    - Light GBM
        XG 부스팅에 비해 가벼워 속도가 빠름.
        drop out 방식 -> 노드를 지우고 불균형한 학습
        hyper parameter = 100개 이상
