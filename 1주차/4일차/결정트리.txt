Decision Tree(결정 트리 모델)
확률적 모델

알고리즘
    Tree를 만들기 위해 Y/N 질문을 반복하며 학습
    노드 + 엣지
    중요 노드를 위에 설정

지니 불순도(gini impurity) = 손실함수
    모델이 제대로 fitting 되었는지 평가하는 기준
    최적의 hyper parameter인지 판단
    낮을수록 최적화
    Entropy(불확실성)

hyper parameter
    max_depth : 트리 최대 깊이, 값이 클수록 모델의 복잡도가 올라감
    max_leaf_nodes : 리프 노드의 최대 개수
    min_sample_leaf : 리프 노드를 구성하는 최소 샘플 개수

    깊이가 정해지면 리프 노드 개수는 정해지는거 아님??
    리프 노드가 무조건 O/X로 결정되는 것이 아니기 때문에 개수를 정해주어야 함

장점
    확률모델이기 때문에 정규화 필요 X -> scaling을 하지 않기 때문에 전처리 거의 필요 없음
    확률모델 -> %로 구할 수 있기 때문에 회귀모델로 활용 가능
    직관적 -> 이해 쉬움
    hyper parameter가 많기 때문에 조절할 수 있는 변수가 많다
    트리 구성 시 특성의 중요도를 계산하기 때문에 특성 선택에 활용할 수 있음
    계량 기법들이 많고 성능이 좋음(gradient boosting...) : kaggle 단위(개인 컴퓨터 내에서 돌릴 수 있는 범위)

단점
    트리 깊이가 깊고 복잡해지면 과대적합 위험성 매우 높음
    트리 최대 깊이, 리프 노드 최대 개수를 지정(작을수록 복잡도 내려감)
    리프 노드를 구성하는 최소 data 개수를 지정(클수록 복잡도 내려감)
    노드를 잘못 탔을 때는 보정할 수가 없기 때문에 과대적합 심함

과대적합 제어(가지치기)
    drop out 방식
    적절한 수준에서 트리의 nodes 일부를 자르거나 합쳐 줌으로써 제어


랜덤 포레스트(Random forest)
    여러 개의 결정 트리 모델로 예측한 값을 투표 -> 최종 선택
    hyper parameter, 노드 배치 조절하여 모두 다른 결정 트리로 구성

    장점 : 실제값에 대한 추정값 오차 평균화, 분산 감소, 과적합 감소


grid search
parameter가 3개 이상이면??
3차원으로 만들어서 구분

선형모델 vs 확률모델
x,y에 상관관계가 있으면 선형모델 사용
딥러닝에서는 선형모델을 사용하지 않음 -> 직관적으로 그릴 수 없기 때문에
