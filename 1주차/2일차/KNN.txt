기하적 모델 -> 단위 중요

KNN(K-Nearest Neighbors)
    기하 모델
    주변 data를 보고 새로 들어온 data를 판단
    최근접 data를 기준으로 판단하는 알고리즘
    KNN(k=5)
    k = 홀수로 지정(변수 개수의 배수는 피하기)
    k값이 너무 적으면 과대적합, 너무 많으면 과소적합이 일어남

    Hyperparameter(주요 매개변수) : 사람이 정하는 값
    parameter : 컴퓨터가 정해준 값(그래프 기울기, y절편 등)

    **변수 값 범위 재조정
        차원의 단위(x축, y축)를 조정
        단위를 비교할 수 없는 경우 단위 통일 필요 -> 편차를 통해 통일시킴
            - Min-max normalization
                x-min/max-min (0~1 사이값)
            - Z-score standardization
                (x-평균)/표준편차 = (x-평균)/(분산)^2
        -> 방법에 따라 결과가 달라질 수 있음

    장단점
    새로운 관측치와 각각의 학습 data 사이의 거리를 전부 측정해야 하기 때문에 계산이 오래걸림
        학습시간은 별로 안걸리지만 예측 시간이 오래 걸림 -> 새로운 data가 들어왔을 때 기존 data와의 거리 계산을 시작하기 때문
        -> KNN => lazy algorithm
        -> 실시간 예측해야할 때는 사용하지 않음
        -> 일반 머신러닝은 학습이 오래걸리고 예측시간이 별로 안걸림
    훈련 data set 크기(특성 수, data 수)가 크면 예측이 느려짐
    기하적 모델이기 때문에 data scale 조정 필요
    이해하기 쉽고 조정없이도 성능이 나쁘지 않기 때문에 가볍게 직관적으로 볼 때 사용

1. 유클리디안 거리(Euclidean Distance)
    피타고라스 정리와 동일
    3차원 이상에서도 정의 가능(피타고라스는 2차원에서만 적용가능)
    math.sqrd((x1-x2)^2 + (y1-y2)^2)
    최단거리

2. 맨해튼 거리(Manhattan Distance)
    계산속도 빠름(계산 비용 줄일 수 있음), 목표지점까지 가기만 하면 된다 -> 계산 단순화
    |x1-x2| + |y1-y2|
    
    결과값은 같지만 경우의수가 달라지는데 머신러닝 돌리는데 영향이 있음???



