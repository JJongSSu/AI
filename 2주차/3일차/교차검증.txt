교차검증(cross-validation)
    학습-평가 data를 골고루 설정하여 모델의 안정성을 높이고 과대적합을 감소시키는 통계적 기법
    data1(x_train, y_train)
    data1(x_test, y_test)
    -> test set에 맞게 학습 될 수 있다
    -> 학습 후 검증

holdout-cross-validation
    data를 학습, 검증, 평가 data로 나눔 -> 2번 검증
    학습    검증    평가

k-fold cross-validation : 회귀
    data를 k개로 나눈 후 1번째 세트를 제외하고 학습 -> 1번째 세트를 이용해서 평가(accuracy) -> 마지막 세트까지 반복 -> 각 세트에 대해 평가 
    -> 각 평과 결과의 평균을 구함
    hyper parameter cv = data를 몇 개로 나눌지 결정
    여러 개의 data set을 한가지 모델을 이용해서 평가하는 방식

장점
    모든 data set을 학습과 평가에 활용하기 때문에 안정적이고 정확 -> 통계적 기법으로 과대적합 감소 -> 일반화 도움
    모델이 훈련 data의 변경에 대해 얼마나 민감한지 파악 가능
    data set 크기가 크지 않아도 유용하게 사용 가능

단점    
    여러 번 학습하고 평가하는 과정을 거치기 때문에 계산량 많아짐 -> 시간, 비용 증가

코드
cross_val_score(모델명, 문제, 정답, cv=나눌 개수)

k-fold
cross_validate
cross_val_score
stratified


