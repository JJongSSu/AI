비지도 학습
    차원축소 : PCA, NMF, t-SNE
    군집 : K-Means, Hierarchial, DBSCAN

차원축소
    어떤 구조를 가정하고, 데이터를 구조에 맞추어 설명하는 방법
    정답 값이 주어지지 않은 입력 data들을 분석하여 공통점이 있는 data끼리 묶어서 그룹핑하는 방식

특징
    정답이 없어 알고리즘이 잘 학습했는지 평가하기 어려움
    EDA, 전처리 단계에서 활용하기도 함
    scale 조정 메서드 -> 지도 정보(supervised information)을 사용하지 않으므로 비지도 방식

종류
    차원 축소 : 원래 data보다 적은 개수의 차원으로 data 표현하는 것
    군집 분석 : data들을 비슷한 것들끼리 일정한 무리 또는 군집으로 나누는 것

차원축소    
    차원이 증가하면 차원을 표현하기 위한 data양이 기하급수적으로 증가 -> data 부피가 커짐 -> 과대적합
    
    차원축소 하는 이유
        복잡한 data를 2차원으로 시각화해서 나타냄
        변수들 사이의 공통적인 정보만 남겨 점수화
        차원을 줄여 과대적합을 피하고 지도학습의 성능을 높임 -> scaler

    PCA
        분산을 가장 많이 설명하는 순서대로 새로운 축을 만들고, 설명량이 적은 축을 없애는 방식
        선형data에 적합

        잠재의미분석 : PCA를 텍스트 data에 적용
        고유이미지 : PCA를 이미지 data에 적용

        분석순서
            분산이 가장 큰 방향의 벡터 찾음
            이 벡터에 직교하면서 가장 큰 정보를 담은 벡터를 찾음
            주성분을 구한다음 원래 데이터 특성 공간에서 표현하기 위해 평균을 더해서 원래대로 돌림

        장점
            data 분포의 분산을 유지한 상태로 차원 축소를 하기 때문에 정확하고 간결하게 데이터표현이 가능
        단점
            최대분산 방향이 feature의 구분을 좋게 만들어준다는 보장은 없음

    t-SNE
        data 포인트 사이의 거리를 가장 잘 보존하는 2차원 표현을 찾는 것
        비선형 data에 적합
        시각화 목적으로 사용 -> feature를 3개 이상 뽑는 경우가 잘 없다

        각 데이터 포인트를 2차원에 무작위로 표현
        원본 특성 공간에서 가까운 포인트는 가깝게 멀리 떨어진 포인트는 멀어지게 만듬 
